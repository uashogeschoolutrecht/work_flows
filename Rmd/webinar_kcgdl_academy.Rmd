---
title: "Open Science at HU"
subtitle: "Introducing the tools"
author: "[Marc Teunis - Presentation Source](https://github.com/uashogeschoolutrecht/work_flows)"
date: "`r Sys.time()`"
always_allow_html: true
output: 
    ioslides_presentation
widescreen: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      error = FALSE,
                      message = FALSE)

image_dir <- here::here(
  "images"
)

## packages
library(tidyverse)

```

## Contents

 - Part 1; Introducing Open Science
 - Part 2; Managing your project files and data with 'Guerilla Analytics'
 - Part 3; Open Science @HU
 

# Part 1; Introducing Open Science

 1. When things go wrong 
 1. Why Open Science?
 1. The need for learning programming
 1. Open Science tools

## Do you recognize this!

<p style="font-size:10px"><i>from: https://medium.com/@jameshoareid/final-pdf-finalfinal-pdf-actualfinal-pdf-cae61ab1d94c</i></p>
```{r, dpi=70}
knitr::include_graphics(
  file.path(
  image_dir,
    "final_final.png"
  )
)

```

## Sometime things go wrong!

<i>"...in science, three things matter:</i> 

 1. the data, 
 1. the methods used to collect the data [...], and 
 1. the logic connecting the data and methods to conclusions,

everything else is a distraction."

<p style="font-size:14px"><i>[Brown, Kaiser & Allison, PNAS, 2018](https://doi.org/10.1073/pnas.1708279115)</p></i>

## `Gollums` lurking about

```{r, dpi = 80}
knitr::include_graphics(
  file.path(
    image_dir,
    "gollum_climbing.jpg"
  )
)
```

<p style="font-size:14px">[Brown, Kaiser & Allison, 2018; PNAS](https://doi.org/10.1073/pnas.1708279115)</p>

"In one case, a group accidentally used reverse-coded variables, making their conclusions the opposite of what the data supported."

"In another case, authors received an incomplete dataset because entire categories of data were missed; when corrected, the qualitative conclusions did not change, but the quantitative conclusions changed by a factor of >7"

## Connecting data to methods to conclusions

How would you 'describe' the steps of an analysis or creation of a graph when you use GUI based software?

```{r, dpi = 60}
knitr::include_graphics(
  file.path(
    image_dir,
    "messy_steps.jpg"
  )
)
```

## Programming is essential for Open Science

 - Only programming an analysis (or creation of a graph) records every step
 - Learning to use a programming language to perform data analysis and create graphs takes time but pays of at the long run, (for all of science)

**(Literate) programming is a way to connect narratives to data, methods and results**
```{r, echo=TRUE}
knitr::include_graphics(file.path(image_dir,"rmd_printscr.png"))
```

## To  replicate a scientific study we need at least:

 > - Scientific context, research questions and state of the art [P]
 > - (Experimental) model or characteristics of population or matter studied [P]
 > - Data that was generated and corresponding meta data [D]
 > - **Exact** (experimental) design of the study [P, D, C]
 > - Exploratory data analysis of the data [C]
 > - **Exact** methods that were used to conduct any formal inference [_P_, C]
 > - Model diagnostics [_C_]
 > - Interpretations of the results/model fitting process [_P_, _C_]
 > - Conclusions and academic scoping of the results [P]
 > - **Access to all of the above** [OAcc, OSrc]

<p style="font-size:14px">$P = Publication$, $D = Data$, $C = Code$, $OAcc = Open\ Access$, $OSrc = Open\ Source$ </p> 

## Example; The Open Science Framework [OSF](https://osf.io/)
```{r}
knitr::include_graphics(
  here::here(
    "images",
    "cos-shield.png")
)
```

$Reproducible\ Science = P + D + C + OAcc + OSrc$ 

**OSF has it all**

## OSF - Reproducibility Project: Psychology

 - 100 publications in Psychology journals
 - Results form half of these publications could be reproduced
 - Full access to P, D and C in [OSF](https://osf.io/ezcuj/)
 - The publication is not published in an OAcc journal
 - [The submitted manuscript is available here](http://pps.sagepub.com/content/7/6/657.abstract)
 - [The R code used is available here](https://osf.io/fkmwg/)  
 
 $RP:Psychology = P + D + C + OSrc$

## Tools to enable Open Science (1/3)

1 - Data Science programming languages

```{r, dpi = 80}
knitr::include_graphics(
  file.path(
    image_dir,
    "data_science_languages",
    "Dia1.jpg"
  )
)
```


## Tools to enable Open Science (2/3)

2 - Data Science infrastructure & software

```{r, dpi = 80}
knitr::include_graphics(
  file.path(
    image_dir,
    "data_science_languages",
    "Dia2.jpg"
  )
)
```

## Tools to enable Open Science (3/3)

3 - Data Science learning tools

```{r, dpi = 80}
knitr::include_graphics(
  file.path(
    image_dir,
    "data_science_languages",
    "Dia3.jpg"
  )
)
```

## A short example of reproducible science

Assume we have the following question:

"Which of 4 types of chairs takes the least effort to arise from when seated in?"

We have the following setup:

 - 4 different types of chairs
 - 9 different subjects (probably somewhat aged)
 - Each subject is required to provide a score (from 6 to 20, 6 being very lightly streneous, 20 being very very extremely streneous) when arising from each of the 4 chairs.

To analyze this experiment statistically,  
the model would need to include: the rating score as the **measured (or dependent) variable**, the type of chair as the **experimental factor** and the subject as the **blocking factor**

## Mixed effects models

A typical analysis method for this type of randomized block design is a so-called 'multi-level' or also called 'mixed-effects' or 'hiarachical' models. An analysis method much used in clinical or biological scientific practice. 
 
You could also use one-way ANOVA but I will illustrate why this is not a good idea 

## What do we need to replicate the science of this experiment?

I will illustrate: 
 
 - the data and an exploratory graph, 
 - the statistical model, 
 - the model results (statistical significance) and   
 - the conclusions 
 
in the next four slides. Hopefully this will illustrate the power of using literate programming to communicate such an analysis. 

<p style="font-size:14px">[Example reproduced from: Pinheiro and Bates, 2000, _Mixed-Effects Models in S and S-PLUS_, Springer, New York.](https://cran.r-project.org/web/packages/nlme/index.html)</p>
 
## The data of the experiment

<p style="font-size:14px">[Wretenberg, Arborelius & Lindberg, 1993](https://doi.org/10.1080/00140139308967910)</p>


```{r, echo=TRUE}
library(nlme)
ergoStool %>% as_tibble()
```

## An exploratory graph
```{r}
set.seed(123)
plot_ergo <- ergoStool %>%
  ggplot(aes(x = reorder(Type, effort), y = effort)) + 
  geom_boxplot(colour = "darkgreen", outlier.shape = NA) + 
  geom_jitter(aes(colour = reorder(Subject, -effort)), 
              width = 0.2, size = 3) +
  scale_colour_manual(values = c("red","blue", "green", "darkblue", "darkgreen", "purple", "grey", "black", "darkgrey")) +
  ylab("Effort (Borg scale score)") +
  xlab("Chair type") + 
  guides(colour=guide_legend(title="Subject id")) +
  theme_bw()
plot_ergo
```

## Mind the variability per subject, what do you see?

 - Can you say something about within-subject variability (mind 'Red')?
 - Can you say something about between-subject variability (mind 'Red', vs 'Black')?
 - Which chair type takes, on average the biggest effort to arise from (note the Boxplot overlay?
 
```{r, fig.width=5, fig.height=3}
plot_ergo
```

## The statistical model, and model summary
The model can be specified (in R) by a model formula. The left side of the formula is the dependent variable, the right side are the 'predictors'. Here we include a `fixed` and a `random` term to the model (as is common for mixed-effects models)

```{r, echo=TRUE}
## the lme() function is part of the nlme package for mixed effects modelling in R
ergo_model <- lme(
  data = ergoStool,
  fixed = effort ~ Type,
  random = ~1 | Subject)
```

<p style="font-size:14px">[Example reproduced from: Pinheiro and Bates, 2000, _Mixed-Effects Models in S and S-PLUS_, Springer, New York.](https://cran.r-project.org/web/packages/nlme/index.html)</p>

## The statistical results
```{r}
result <- ergo_model %>% summary() 
result$tTable %>% as.data.frame() %>% knitr::kable()
```

## Model diagnostics 

 - Diagnostics of a fitted model is important step in a statistical analysis
 - In most scientific papers the details are lacking 
 - Did the authors preform this step? Or did they not report it?
 
A residual plot shows the 'residual' error after fitting the model ('unexplained variance'). Under the Normality assumption standardized residuals should:
 
 1. Be normally distributed around 0
 1. Display no obvious 'patters'
 1. Should display overall equal 'spread' above and below 0
 
## Residual plot
```{r, echo=TRUE}
plot(ergo_model)
## type 'pearson' extracts the standardized residuals
## a signifiant Shapiro indicated deviation from a Normal distribution
shapiro.test(residuals(ergo_model, type = "pearson"))
```

# Part2; Managing your project with 'Guerilla Analytics'

 1. Files and folders / Project structure
 1. Data-formats
 1. Coding variables
 1. Factor levels (labels)
 1. Data integrity (md5sums)

## The Guerilla Analytics Principles

 - Principle 1: Space is cheap, confusion is expensive
 - <mark>Principle 2: Prefer simple, visual project structures and conventions</mark>
 - <mark>Principle 3: Prefer automation with program code</mark>
 - Principle 4: Maintain a link between data on the file system, data in the analytics environment, and data in work products
 - <mark>Principle 5: Version control changes to data and analytics code</mark> 
 - Principle 6: Consolidate team knowledge in version-controlled builds 
 - <mark>Principle 7: Prefer analytics code that runs from start to finish</mark>

## Principle 2: Project structure   
```{r}
fs::dir_tree(here::here("data-raw"))
```

## Principle 3: Automation
Assume we daily want to download the COVID-19 case data from the ECDC website.
We could do this manually, every day

Better: Write a small R script that downloads the data and stores it (with a date-stamp in the file name) in the right folder.

The script is included in 

[Windows](https://www.r-bloggers.com/how-to-run-r-from-the-task-scheduler/)
[RStudio-server / Linux]()



## Principle 5: Version control for data and code - Git/Github



## Principle 7; Code that runs from start to end
```{r, dpi=400, fig.align='right'}
knitr::include_graphics(
  file.path(
  image_dir,
  "one_ring.jpg")
)
```

 - In R we have RMarkdown
 - In Engineering, Maths and Physics, LaTeX is used
 - In Journalism and marketing: HTML, CSS are used
 - In webdevelopment Java and Java Script are used
 - RMarkdown rules them all!





Part 3; Data files and formats




# File names and file formats

# Data structure -> A context free solution

# Wide data-formats

# Long data-formats



 1. Data integrity (md5sums)
 1. Factor levels (labels)
 1. FAIR principles
 1. HU ResearchDrive - using Rsync to tranfer and check files


## Meta data
http://rd-alliance.github.io/metadata-directory/standards/


# Part 3; Open Science @HU


 
## Access Research Drive via Rclone

[HU-RD Wiki](https://wiki.surfnet.nl/display/RDRIVE/4.+Access+Research+Drive+via+Rclone)

In this part you will find documentation about rclone. Rclone is the rsync for cloud storage. Information on how to install rclone and other things may be found at: https://rclone.org.

Apart from being an rsync-type tool for cloud storage, it has the following features:

    MD5/SHA1 hashes checked at all times for file integrity
    Timestamps preserved on files
    Partial syncs supported on a whole file basis
    Copy mode to just copy new/changed files
    Sync (one way) mode to make a directory identical
    Check mode to check for file hash equality
    Can sync to and from network, eg two different cloud accounts
    Optional encryption ( Crypt )
    Optional FUSE mount ( rclone mount )

Rclone configuration

In order to use Rclone, an Rclone configuration must be created first. Start the rclone config utility to generatie a Rclone configuration;

        rclone config
      

Then you get the following options:

    Select n for new remote and choose the name, RD in this example
    Select the storage system. Select Webdav
    Fill in the URL. In this case this will be: https://researchdrive.surfsara.nl/remote.php/webdav
    Select the type of webdav storage system. Select Owncloud
    Type in your user name.
    Select: y) Yes type in my own password
    Type in your password and type it in again for confirmation. This is the webdav password you have in the Research Drive web page at Settings->Security->WebDAV passwords
    Confirm your settings

The rclone.conf file resides in .config/rclone/ by default and will contain the following contents:

        [RD]
    type = webdav
    url = https://researchdrive.surfsara.nl/remote.php/webdav/
    vendor = owncloud
    user = <user name>
    pass = <encrypted password>
              

If you want to put the rclone.conf file in a non-standard place, then that is possible too, but then you need to run your rclone commands in the following manner:

        rclone --config /path/to/rclone.conf <command> .......
              


Timeout

It is important to set the '–timeout' option high enough. As a rule of thumb, set it to 10 minutes for every GB of the biggest file in a collection. So if the biggest file you want to upload in a collection is 10GB, set --timeout 100m

This may look ridiculously large, but it provides a safe margin to avoid problems with timeout issues
Avoid locking usage

Use also the flag `--use-cookies` to return always on the same Research Drive backend, to prevent file lock between Research Drive backends.
Command examples

Listing destination directory

To get an overview of your current files on Research Drive.

      rclone ls RD:

Copy source directory to destination directory

Copy the source to the destination. Doesn’t transfer unchanged files, testing by size and modification time or MD5SUM. Doesn’t delete files from the destination.
If my/destination/folder doesn’t exist, it is created and the contents of /my/folder goes there.

        rclone copy /my/folder RD:my/destination/folder
              


Working with large objects

When you want to upload large files to Research Drive, we recommend using a timeout of 10 minutes per gigabyte of the largest source file.
As an example, the largest file in the source directory is 5GB. Calculating the argument for –timeout gives: 10 minutes x 5GB = 50 minutes.

        rclone copy --use-cookies --timeout 50m ~/my_5gb_file.bin RD:my/destination/folder
              


Sync source directory with destination directory

Sync the source to the destination, changing the destination only. Doesn’t transfer unchanged files, testing by size and modification time or MD5SUM. Destination is updated to match source, including deleting files if necessary.

        rclone sync /my/folder RD:my/destination/folder
              

Important: Since this can cause data loss, test first with the –dry-run flag to see exactly what would be copied and deleted.

Note that files in the destination won’t be deleted if there were any errors at any point.

If my/destination/folder doesn’t exist, it is created and the contents of /my/folder goes there.



Check if files in the source and destination match

Checks the files in the source and destination match. It compares sizes and hashes (MD5 or SHA1) and logs a report of files which don’t match. It doesn’t alter the source or destination.

        rclone check /my/folder RD:my/destination/folder

  

  

Use rclone to mount file systems in user space

Using rclone to mount a file system in user space is done as follows:

        rclone mount --use-cookies --timeout 15m RD:[path/to/dir] /path/to/local/mount
              

The flag `--use-cookies` is needed, to get you always on the same Research Drive backend, to prevent file lock between backends. The timeout flag is useful for uploading large files, we recommend using a timeout of 10 minutes per gigabyte of the largest source file.

You can unmount this file system by:

        fusermount -u /path/to/local/mount
              

An example is shown below:

## md5sums

On Windows
```
CertUtil -hashfile <path to file> MD5

```
Using Rclone
```
rclone md5sum remote:path [flags]
``` 
 
 
 